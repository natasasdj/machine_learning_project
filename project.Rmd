---
title: 'Practical Machine Learning - Course Project'
output: html_document
---

## Executive Summary

The goal of the project is to predict the way a person performs an excercise using data from accelerometers on her belt, forearm, arm, and dumbell.

First we remove obviously non-relevant variables, and then we use a random forest model both as a mean to select predictor variables and as a final predictive model. 

## Pre-processing and Data Splitting

We remove variables that have a lot of missing values. Also we remove variables that we obviously should not use in predicting the outcome: `X`,`raw_timestamp_part_1`, `raw_timestamp_part_2`, `cvtd_timestamp`, `new_window`, `num_window`.

```{r,results='hide', message=FALSE, warning=FALSE}
training<-read.csv("training_data.csv")
tr_na<-sapply(training,function(x){sum(is.na(x))/length(x)})
training1<-training[tr_na<0.2]
tr_bl<-sapply(training1,function(x){sum(x=="")/length(x)})
training2<-training1[tr_bl<0.2]
training3<-training2[,-c(1,3,4,5,6,7)]
```

We split data into 3 data sets: testing, training and validation. We use the training and validation set to choose and train our predictive model and to estimate the out of sample error, while we use the test set only at the end to verify the estimated error.

```{r,results='hide', message=FALSE, warning=FALSE}
library(caret); set.seed(1829)
intest<-createDataPartition(training3$classe,p=0.2,list=FALSE)
test_data <- training3[intest,]
train_data <- training3[-intest,]
incv<-createDataPartition(train_data$classe,p=0.2,list=FALSE)
test_cv <- train_data[incv,]
train_data <- train_data[-incv,]
```

## Model and Predictors Selection 

We use a random forest model. It has a low bias and a low variance and it can work well with a large number of predictor variables. First, we try to run the model using all variables except theoutcome as predictors. With the whole training data-set it requires a large processing time. Because of this we run the model only on the part of the training data-set. Then, we find important variables for the classification in this model using the `varImp` function. We repeat this process, and estimate the out of sample errors on the validation data-set. In the both cases the out of sample accuracy is above 96 %.

```{r,results='hide', cache=TRUE, message=FALSE, warning=FALSE}
insmall<- createDataPartition(train_data$classe,p=0.25,list=FALSE)
train_small <- train_data[insmall,]
fit1 <- train(classe ~ .,method="rf",data=train_small)
```
```{r,results='hide', message=FALSE, warning=FALSE}
imp1<-varImp(fit1)
i<-cbind(imp1$importance,rownames(imp1$importance))
imp_pred1<-as.character(i[i$Overall>=10,2])
```
```{r,results='hide', cache=TRUE, message=FALSE, warning=FALSE} 
set.seed(1519)
insmall<- createDataPartition(train_data$classe,p=0.25,list=FALSE)
train_small <- train_data[insmall,]
fit2 <- train(classe ~ .,method="rf",data=train_small)
imp2<-varImp(fit2)
i<-cbind(imp2$importance,rownames(imp2$importance))
imp_pred2<-as.character(i[i$Overall>=10,2])
``` 
```{r,eval=FALSE} 
pred <- predict(fit1,test_cv)
confusionMatrix(pred,test_cv$classe)
pred <- predict(fit2,test_cv)
confusionMatrix(pred,test_cv$classe)
```

Finally, we select the set of predictor variables as the union of the important predictors found in the previous two model fits `fit1` and `fit2`. And, we use these predictors to fit the random forest model using the whole training data set. We expect that this model has a better accuracy than the previous two models.


## Resulting Model

We run the random forest model on the whole training data set with the predictor variables selected as shown in the previous section.

```{r,results='hide', cache=TRUE, message=FALSE, warning=FALSE} 
set.seed(29181519)
imp_pred<-union(imp_pred1,imp_pred2)
fit <- train(train_data[,imp_pred],train_data$classe,method="rf")
```
We expect that the out of sample accuracy is 96%.
```{r, message=FALSE, warning=FALSE}
fit$finalModel
``` 

And we test the fitted model against the test data-set.
```{r, message=FALSE, warning=FALSE}
pred <- predict(fit,test_data)
confusionMatrix(pred,test_data$classe)
``` 
We see that the model has a very good performance with the accuracy above 98 %.